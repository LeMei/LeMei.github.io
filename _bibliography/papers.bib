---
---

@string{aps = {American Physical Society,}}

@inproceedings{ashby-weir-2020-leveraging,
    title = "Towards Structure-aware Paraphrase Identification with Phrase Alignment Using Sentence Encoders",
    author = "Peng, Qiwei  and
      Weir, David and
      Weeds, Julie",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "South Korea",
    publisher = "International Committee on Computational Linguistics",
    abbr = {COLING},
    award = {Oral},
    selected = {true}
}

@inproceedings{peng-etal-2022-predicate,
    title = "Predicate-Argument Based Bi-Encoder for Paraphrase Identification",
    author = "Peng, Qiwei  and
      Weir, David  and
      Weeds, Julie  and
      Chai, Yekun",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.382",
    doi = "10.18653/v1/2022.acl-long.382",
    pages = "5579--5589",
    abstract = "Paraphrase identification involves identifying whether a pair of sentences express the same or similar meanings. While cross-encoders have achieved high performances across several benchmarks, bi-encoders such as SBERT have been widely applied to sentence pair tasks. They exhibit substantially lower computation complexity and are better suited to symmetric tasks. In this work, we adopt a bi-encoder approach to the paraphrase identification task, and investigate the impact of explicitly incorporating predicate-argument information into SBERT through weighted aggregation. Experiments on six paraphrase identification datasets demonstrate that, with a minimal increase in parameters, the proposed model is able to outperform SBERT/SRoBERTa significantly. Further, ablation studies reveal that the predicate-argument based component plays a significant role in the performance gain.",
    selected={true},
    abbr={ACL},
    award = {Oral}
}

@inproceedings{peng-etal-2021-structure,
    title = "Structure-aware Sentence Encoder in Bert-Based {S}iamese Network",
    author = "Peng, Qiwei  and
      Weir, David  and
      Weeds, Julie",
    booktitle = "Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.repl4nlp-1.7",
    doi = "10.18653/v1/2021.repl4nlp-1.7",
    pages = "57--63",
    abstract = "Recently, impressive performance on various natural language understanding tasks has been achieved by explicitly incorporating syntax and semantic information into pre-trained models, such as BERT and RoBERTa. However, this approach depends on problem-specific fine-tuning, and as widely noted, BERT-like models exhibit weak performance, and are inefficient, when applied to unsupervised similarity comparison tasks. Sentence-BERT (SBERT) has been proposed as a general-purpose sentence embedding method, suited to both similarity comparison and downstream tasks. In this work, we show that by incorporating structural information into SBERT, the resulting model outperforms SBERT and previous general sentence encoders on unsupervised semantic textual similarity (STS) datasets and transfer classification tasks.",
    selected={false},
    abbr={RepL4NLP}
}

@inproceedings{bertolini-etal-2021-representing,
    title = "Representing Syntax and Composition with Geometric Transformations",
    author = "Bertolini, Lorenzo  and
      Weeds, Julie  and
      Weir, David  and
      Peng, Qiwei",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.296",
    doi = "10.18653/v1/2021.findings-acl.296",
    pages = "3343--3353",
    abbr={Findings@ACL}
}

@article{xia2021aroused,
  title={Aroused and Impulsive Effects of Colour Stimuli on Lateral and Logical Abilities},
  author={Xia, Guobin and Li, Muzi and Henry, Philip and Westland, Stephen and Queiroz, Francisco and Peng, Qiwei and Yu, Luwen},
  journal={Behavioral Sciences},
  volume={11},
  number={2},
  pages={24},
  year={2021},
  publisher={MDPI},
  abbr={Behav Sci}
}
