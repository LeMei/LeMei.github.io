---
---

@article{hu2024unifying,
  title={Unifying emotion-oriented and cause-oriented predictions for emotion-cause pair extraction},
  author={Hu, Guimin and Zhao, Yi and Lu, Guangming},
  journal={Neural Networks},
  pages={106431},
  year={2024},
  publisher={Elsevier},
  selected={false},
  abbr={NN}
}

@inproceedings{hu2022unimse,
  title={UniMSE: Towards Unified Multimodal Sentiment Analysis and Emotion Recognition},
  author={Hu, Guimin and Lin, Ting-En and Zhao, Yi and Lu, Guangming and Wu, Yuchuan and Li, Yongbin},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={7837--7851},
  year={2022},
  selected={true},
  url="https://aclanthology.org/2022.emnlp-main.534/",
  code="https://github.com/LeMei/UniMSE",
  abbr={EMNLP}
}

@article{hu2021fss,
  title={FSS-GCN: A graph convolutional networks with fusion of semantic and structure for emotion cause analysis},
  author={Hu, Guimin and Lu, Guangming and Zhao, Yi},
  journal={Knowledge-Based Systems},
  volume={212},
  pages={106584},
  year={2021},
  publisher={Elsevier},
  selected={false},
  url="https://www.sciencedirect.com/science/article/pii/S0950705120307139",
  code="https://github.com/LeMei/FSS-GCN",
  abbr={KBS}
}

@inproceedings{hu2021bidirectional,
  title={Bidirectional hierarchical attention networks based on document-level context for emotion cause extraction},
  author={Hu, Guimin and Lu, Guangming and Zhao, Yi},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2021},
  pages={558--568},
  year={2021},
  selected={False},
  url="https://aclanthology.org/2021.findings-emnlp.51/",
  abbr={EMNLP Findings}
}

@article{hu2023emotion,
  title={Emotion prediction oriented method with multiple supervisions for emotion-cause pair extraction},
  author={Hu, Guimin and Zhao, Yi and Lu, Guangming},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={31},
  pages={1141--1152},
  year={2023},
  publisher={IEEE},
  selected={true},
  url="https://ieeexplore.ieee.org/abstract/document/10067863",
  code="https://github.com/LeMei/EPO-ECPE",
  abbr={TASLP}
}

@article{hu2024improving,
  title={Improving Representation With Hierarchical Contrastive Learning for Emotion-Cause Pair Extraction},
  author={Hu, Guimin and Zhao, Yi and Lu, Guangming},
  journal={IEEE Transactions on Affective Computing},
  year={2024},
  publisher={IEEE},
  selected={true},
  url="https://ieeexplore.ieee.org/abstract/document/10509759",
  abbr={TAFFC}
}

@article{hu2024unimeec,
  title={UniMEEC: Towards Unified Multimodal Emotion Recognition and Emotion Cause},
  author={Hu, Guimin and Zhu, Zhihong and Hershcovich, Daniel and Seifi, Hasti and Xie, Jiayuan},
  journal={Findings of the Association for Computational Linguistics: EMNLP 2024},
  year={2024},
  selected={false},
  url="https://arxiv.org/pdf/2404.00403",
  code="https://github.com/LeMei/causal-unimeec/tree/main",
  abbr={EMNLP Findings}
}

@article{hu2022exploration,
  title={An exploration of mutual information based on emotion--cause pair extraction},
  author={Hu, Guimin and Zhao, Yi and Lu, Guangming and Yin, Fanghao and Chen, Jiashan},
  journal={Knowledge-Based Systems},
  volume={256},
  pages={109822},
  year={2022},
  publisher={Elsevier},
  selected={false},
  abbr={KBS}
}

@inproceedings{hu2020emotion,
  title={Emotion-cause joint detection: A unified network with dual interaction for emotion cause analysis},
  author={Hu, Guimin and Lu, Guangming and Zhao, Yi},
  booktitle={Natural Language Processing and Chinese Computing: 9th CCF International Conference, NLPCC 2020, Zhengzhou, China, October 14--18, 2020, Proceedings, Part I 9},
  pages={568--579},
  year={2020},
  organization={Springer},
  selected={false},
  abbr={NLPCC}
}

@inproceedings{zhu2024towards,
  title={Towards Multi-modal Sarcasm Detection via Disentangled Multi-grained Multi-modal Distilling},
  author={Zhu, Zhihong and Cheng, Xuxin and Hu, Guimin and Li, Yaowei and Huang, Zhiqi and Zou, Yuexian},
  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  pages={16581--16591},
  year={2024},
  selected={false},
  abbr={COLING}
}

@article{li2024foodieqa,
  title={FoodieQA: A Multimodal Dataset for Fine-Grained Understanding of Chinese Food Culture},
  author={Li, Wenyan and Zhang, Xinyu and Li, Jiaang and Peng, Qiwei and Tang, Raphael and Zhou, Li and Zhang, Weijia and Hu, Guimin and Yuan, Yifei and S{\o}gaard, Anders and others},
  journal={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  year={2024},
  selected={false},
  url="https://arxiv.org/pdf/2406.11030",
  code="https://github.com/lyan62/FoodieQA",
  abbr={EMNLP}
}

@article{yin2023modeling,
  title={Modeling data-driven adaptive distributionally robust equilibrium last mile relief network under centrality metric},
  author={Yin, Fanghao and Zhao, Yi and Wang, Dong and Hu, Guimin},
  journal={Applied Mathematical Modelling},
  volume={122},
  pages={614--640},
  year={2023},
  publisher={Elsevier},
  selected={false},
  abbr={AMM}
}

@inproceedings{ijcai2024p739,
  title     = {TFCD: Towards Multi-modal Sarcasm Detection via Training-Free Counterfactual Debiasing},
  author    = {Zhu, Zhihong and Zhuang, Xianwei and Zhang, Yunyan and Xu, Derong and Hu, Guimin and Wu, Xian and Zheng, Yefeng},
  booktitle = {Proceedings of the Thirty-Third International Joint Conference on
               Artificial Intelligence, {IJCAI-24}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Kate Larson},
  pages     = {6687--6695},
  year      = {2024},
  selected={false},
  abbr={IJCAI}
}

@inproceedings{arxiv_2409_07388,
  title     = {Recent Trends of Multimodal Affective Computing: A Survey from NLP Perspective},
  author    = {Hu, Guimin and Xin, Yi and Lyu, Weimin and Huang, Haojian and Sun, Chang and Zhu, Zhihong and Gui, Lin and Cai, Ruichu},
  booktitle = {arXiv preprint arXiv:2409.07388},
  year      = {2024},
  selected={true},
  url="https://arxiv.org/abs/2409.07388",
  code="https://github.com/LeMei/Multimodal-Affective-Computing-Survey",
  abbr={arXiv}
}

@inproceedings{arxiv_2411_02118,
  title     = {Grounding Emotional Descriptions to Electrovibration Haptic Signals},
  author    = {Hu, Guimin and Zhao, Zirui and Heilmann, Lukas and Vardar, Yasemin and Seifi, Hasti},
  booktitle = {arXiv preprint arXiv:2411.02118},
  year      = {2024},
  selected={false},
  url="https://arxiv.org/abs/2411.02118",
  abbr={ACII}
}

@inproceedings{arxiv_2410_19128,
  title     = {Retrieving Implicit and Explicit Emotional Events Using Large Language Models},
  author    = {Hu, Guimin and Seifi, Hasti},
  booktitle = {arXiv preprint arXiv:2410.19128},
  year      = {2024},
  selected={false},
  url="https://arxiv.org/abs/2410.19128",
  abbr={arXiv}
}
@inproceedings{hu2025improving,
  title={Improving Representation with Intra-and Inter-clause Commonsense Injection for Emotion-Cause Pair Extraction},
  author={Hu, Guimin and Xie, Jiayuan},
  booktitle={IEEE Transactions on Audio, Speech and Language Processing},
  year={2025},
  selected={false},
  url="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10830540",
  abbr={TASLP}
}
@inproceedings{hu2025partitioner,
  title     = {PgM: Partitioner Guided Modal Learning Framework},
  author    = {Hu, Guimin and Xin, Yi and Hu, Lijie and Zhu, Zhihong and Seifi, Hasti},
  booktitle = {ACM International Conference on Multimedia},
  year      = {2025},
  selected={true},
  url="https://arxiv.org/abs/2507.11661",
  abbr={MM}
}

@inproceedings{hu2025hapticcap,
  title     = {HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals},
  author    = {Hu, Guimin and Hershcovich, Daniel and Seifi, Hasti},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP},
  year      = {2025},
  selected={true},
  url="https://arxiv.org/pdf/2507.13318?",
  abbr={EMNLP Findings}
}

@inproceedings{hu2025hapticllama,
  title={HapticLLaMA: A Multimodal Sensory Language Model for Haptic Captioning},
  author={Hu, Guimin and Hershcovich, Daniel and Seifi, Hasti},
  journal={arXiv preprint arXiv:2508.06475},
  year={2025},
  selected={true},
  url="https://arxiv.org/pdf/2508.06475",
  abbr={arXiv}
}
}